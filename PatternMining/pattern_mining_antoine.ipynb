{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude des motifs - Antoine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous étudions les motifs présents dans le corpus d'Antoine. \n",
    "1. Dans un premier temps on se base sur les retranscriptions phonétiques d'Antoine issu de l'alphabet phonétique. \n",
    "2. Puis on se base les retranscriptions phonémiques issue de l'alphabet Fançais. \n",
    "3. Finalement, on se base sur les retranscriptions phonétiques d'Antoine que l'on pondèrent par la localisation du phonème dans le mot et par sa \"valeur\" de prononciation.  \n",
    "\n",
    "\n",
    "Dans cette étude, on définit les items comme :\n",
    " - Un mot\n",
    " - Un phonème\n",
    " \n",
    "Pour chaque items on utilise des algorithmes : \n",
    " - Frequent Itemset Mining\n",
    " - Sequential Pattern Extraction\n",
    " \n",
    " Le but de cette étude est d'extraire les motifs fréquents du corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymining import itemmining, assocrules, seqmining\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Lamou\\\\Desktop\\\\MIASHS\\\\TER_a\\\\data')\n",
    "data_antoine = pd.read_csv('data_antoine_final.csv',\n",
    "                           sep = '\\t',\n",
    "                           encoding = 'utf-8',\n",
    "                           index_col=False)\n",
    "\n",
    "# On supprime la colonne qui duplique les index\n",
    "data_antoine = data_antoine.drop(columns = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère les retranscritpions phonétiques et phonémiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_antoine = data_antoine[data_antoine['type'] == 'CHI']\n",
    "pho_antoine = data_antoine[data_antoine['type'] == 'pho']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enfant</th>\n",
       "      <th>age</th>\n",
       "      <th>type</th>\n",
       "      <th>seconde_debut</th>\n",
       "      <th>seconde_fin</th>\n",
       "      <th>contenu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ahaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ajabə</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       enfant      age type  seconde_debut  seconde_fin contenu\n",
       "1228  ANTOINE  1_00_24  pho            NaN          NaN       a\n",
       "1230  ANTOINE  1_00_24  pho            NaN          NaN       a\n",
       "1319  ANTOINE  1_00_24  pho            NaN          NaN    ahaa\n",
       "1326  ANTOINE  1_00_24  pho            NaN          NaN       a\n",
       "1342  ANTOINE  1_00_24  pho            NaN          NaN   ajabə"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pho_antoine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi_antoine.loc[chi_antoine['contenu']=='yyy .'] # Contient les phrases phonémiques 'yyy .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enfant</th>\n",
       "      <th>age</th>\n",
       "      <th>type</th>\n",
       "      <th>seconde_debut</th>\n",
       "      <th>seconde_fin</th>\n",
       "      <th>contenu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ahaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ajabə</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       enfant      age type  seconde_debut  seconde_fin contenu\n",
       "1228  ANTOINE  1_00_24  pho            NaN          NaN       a\n",
       "1230  ANTOINE  1_00_24  pho            NaN          NaN       a\n",
       "1319  ANTOINE  1_00_24  pho            NaN          NaN    ahaa\n",
       "1326  ANTOINE  1_00_24  pho            NaN          NaN       a\n",
       "1342  ANTOINE  1_00_24  pho            NaN          NaN   ajabə"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pho_antoine = pho_antoine['contenu']\n",
    "pho_antoine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppression des valeur NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pho_antoine = pho_antoine.dropna(subset=['type', 'contenu'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les lignes du corpus strictement égales à un item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enfant</th>\n",
       "      <th>age</th>\n",
       "      <th>type</th>\n",
       "      <th>seconde_debut</th>\n",
       "      <th>seconde_fin</th>\n",
       "      <th>contenu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       enfant      age type  seconde_debut  seconde_fin contenu\n",
       "1228  ANTOINE  1_00_24  pho            NaN          NaN       a\n",
       "1230  ANTOINE  1_00_24  pho            NaN          NaN       a\n",
       "1326  ANTOINE  1_00_24  pho            NaN          NaN       a\n",
       "1363  ANTOINE  1_00_24  pho            NaN          NaN       a\n",
       "1385  ANTOINE  1_00_24  pho            NaN          NaN       a"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pho_antoine.loc[pho_antoine['contenu'] == 'a'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les lignes du corpus contenant un item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_item_in_rows(item, df):\n",
    "    '''\n",
    "        param  : item (str)\n",
    "                 df (pd.DataFrame)\n",
    "        return : Un pd.DataFrame contenant les lignes du corpus qui contiennent un item\n",
    "    '''\n",
    "    list = []\n",
    "    f=0\n",
    "    for i in df['contenu']:            # On parcour la colonne contenu\n",
    "        if item in i:                  # Pour chaque ligne de 'contenu'\n",
    "            list.append(df.iloc[f])\n",
    "        f+=1\n",
    "    return pd.DataFrame(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enfant</th>\n",
       "      <th>age</th>\n",
       "      <th>type</th>\n",
       "      <th>seconde_debut</th>\n",
       "      <th>seconde_fin</th>\n",
       "      <th>contenu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_00_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ə bɛ̃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5858</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_01_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bɛ̃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6856</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_01_24</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bɛ̃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10170</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_03_16</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bɛ̃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11228</th>\n",
       "      <td>ANTOINE</td>\n",
       "      <td>1_03_16</td>\n",
       "      <td>pho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bɛ̃</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        enfant      age type  seconde_debut  seconde_fin contenu\n",
       "1556   ANTOINE  1_00_24  pho            NaN          NaN   ə bɛ̃\n",
       "5858   ANTOINE  1_01_24  pho            NaN          NaN     bɛ̃\n",
       "6856   ANTOINE  1_01_24  pho            NaN          NaN     bɛ̃\n",
       "10170  ANTOINE  1_03_16  pho            NaN          NaN     bɛ̃\n",
       "11228  ANTOINE  1_03_16  pho            NaN          NaN     bɛ̃"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item_in_rows('bɛ̃', pho_antoine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des valeurs nan\n",
    "#df_pho = pd.DataFrame(pho_antoine[{'age', 'contenu'}]).dropna()\n",
    "#df_pho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous avons nos données préparées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame selon la structure établie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf = pho_antoine[{'age', 'contenu'}].groupby('age') # On regroupe les phrases par l'age de l'enfant (par enregistrement)\\ndf = pd.DataFrame(df)\\nlen(df[1][0]['contenu']) # Pour le 1er enregistrement on a 186 phrases\\ndf[1][0]['contenu'].str.split(' ').tolist()\\ndf[1][1]['contenu'].values\\nsequences = []\\nfor i in range(df.shape[0]):\\n    tup = tuple(df[1][i]['contenu'].str.split(' ').tolist())\\n    sequences.append(tup)\\nsequences[0] # On retrouve notre liste des mots par phrase du 1er enregistrement\\nlen(sequences[0])\\nrelim_input = itemmining.get_relim_input(sequences[6])\\nitem_sets = itemmining.relim(relim_input, min_support=50)\\nitem_sets\\nfreq_seqs = seqmining.freq_seq_enum(sequences[30], 10)\\nfor seq in freq_seqs:\\n    print(seq)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df = pho_antoine[{'age', 'contenu'}].groupby('age') # On regroupe les phrases par l'age de l'enfant (par enregistrement)\n",
    "df = pd.DataFrame(df)\n",
    "len(df[1][0]['contenu']) # Pour le 1er enregistrement on a 186 phrases\n",
    "df[1][0]['contenu'].str.split(' ').tolist()\n",
    "df[1][1]['contenu'].values\n",
    "sequences = []\n",
    "for i in range(df.shape[0]):\n",
    "    tup = tuple(df[1][i]['contenu'].str.split(' ').tolist())\n",
    "    sequences.append(tup)\n",
    "sequences[0] # On retrouve notre liste des mots par phrase du 1er enregistrement\n",
    "len(sequences[0])\n",
    "relim_input = itemmining.get_relim_input(sequences[6])\n",
    "item_sets = itemmining.relim(relim_input, min_support=50)\n",
    "item_sets\n",
    "freq_seqs = seqmining.freq_seq_enum(sequences[30], 10)\n",
    "for seq in freq_seqs:\n",
    "    print(seq)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Retranscription phonétique\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item : mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pho_antoine['contenu'].str.split(' ').tolist()\n",
    "#transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6089\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ahaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ajabə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bwaha</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0      a\n",
       "2   ahaa\n",
       "3  ajabə\n",
       "4    abi\n",
       "5  bwaha"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_col = pd.DataFrame(transactions)\n",
    "item_col = pd.unique(item_col.values.ravel())\n",
    "item_col = pd.DataFrame(item_col)\n",
    "item_col = item_col.dropna()\n",
    "print(len(item_col))\n",
    "item_col.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre collection d'item est de 6089 mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Frequent Itemset Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Quelle valeur de support minimum ? : A partir de quelle fréquence peut-on considérer qu'un item set est fréquent ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "relim_input = itemmining.get_relim_input(transactions)\n",
    "item_sets = itemmining.relim(relim_input, min_support=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{frozenset({'fɛ'}): 102,\n",
       " frozenset({'twa'}): 103,\n",
       " frozenset({'na'}): 104,\n",
       " frozenset({'χ'}): 104,\n",
       " frozenset({'u'}): 108,\n",
       " frozenset({'isi'}): 109,\n",
       " frozenset({'pø'}): 114,\n",
       " frozenset({'d'}): 116,\n",
       " frozenset({'tu'}): 118,\n",
       " frozenset({'mː'}): 121,\n",
       " frozenset({'dɑ̃'}): 124,\n",
       " frozenset({'wiʃ'}): 125,\n",
       " frozenset({'ø'}): 128,\n",
       " frozenset({'ɑ̃'}): 128,\n",
       " frozenset({'fe'}): 129,\n",
       " frozenset({'kwa'}): 129,\n",
       " frozenset({'ɛl'}): 137,\n",
       " frozenset({'ja'}): 138,\n",
       " frozenset({'t'}): 138,\n",
       " frozenset({'kɔm'}): 139,\n",
       " frozenset({'vwatyʁ'}): 139,\n",
       " frozenset({'si'}): 148,\n",
       " frozenset({'aː'}): 154,\n",
       " frozenset({'papa'}): 163,\n",
       " frozenset({'mɛ'}): 167,\n",
       " frozenset({'il'}): 173,\n",
       " frozenset({'də'}): 179,\n",
       " frozenset({'vø'}): 179,\n",
       " frozenset({'lɛ'}): 189,\n",
       " frozenset({'dø'}): 197,\n",
       " frozenset({'yn'}): 199,\n",
       " frozenset({'ɛ̃'}): 201,\n",
       " frozenset({'ɔ'}): 209,\n",
       " frozenset({'mamɑ̃'}): 211,\n",
       " frozenset({'va'}): 211,\n",
       " frozenset({'ʒə'}): 212,\n",
       " frozenset({'bɛ̃'}): 214,\n",
       " frozenset({'o'}): 220,\n",
       " frozenset({'ɔ̃'}): 225,\n",
       " frozenset({'ty'}): 237,\n",
       " frozenset({'œ̃'}): 245,\n",
       " frozenset({'mwa'}): 249,\n",
       " frozenset({'ə'}): 253,\n",
       " frozenset({'œ̃̃'}): 270,\n",
       " frozenset({'se'}): 290,\n",
       " frozenset({'nɑ̃'}): 307,\n",
       " frozenset({'ʒ'}): 318,\n",
       " frozenset({'e', 'ʒ'}): 123,\n",
       " frozenset({'lə'}): 342,\n",
       " frozenset({'l'}): 368,\n",
       " frozenset({'X'}): 441,\n",
       " frozenset({'ɛ'}): 485,\n",
       " frozenset({'i'}): 487,\n",
       " frozenset({'sɛ'}): 573,\n",
       " frozenset({'sa', 'sɛ'}): 143,\n",
       " frozenset({'nɔ̃'}): 579,\n",
       " frozenset({'m'}): 627,\n",
       " frozenset({'sa'}): 648,\n",
       " frozenset({'pa'}): 700,\n",
       " frozenset({'wi'}): 855,\n",
       " frozenset({'e'}): 856,\n",
       " frozenset({'la'}): 1023,\n",
       " frozenset({'a'}): 1427}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assocation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(frozenset({'ʒ'}), frozenset({'e'}), 123, 0.3867924528301887)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = assocrules.mine_assoc_rules(item_sets, min_support=2, min_confidence=0.3)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment interpréter ces résultats ?\n",
    " - Les phrases contenant un 'ʒ' elle ont 39% de chance de contenir un 'e'\n",
    " - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Pattern Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a'],\n",
       " ['a'],\n",
       " ['ahaa'],\n",
       " ['a'],\n",
       " ['ajabə'],\n",
       " ['abi'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['bwaha'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['yi'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['ɛ'],\n",
       " ['a'],\n",
       " ['aaaaaa'],\n",
       " ['ɛdəd'],\n",
       " ['aa'],\n",
       " ['abəbə', 'X'],\n",
       " ['ə', 'bɛ̃'],\n",
       " ['hihi'],\n",
       " ['a'],\n",
       " ['wa'],\n",
       " ['datatata'],\n",
       " ['tata', 'X'],\n",
       " ['hɛ'],\n",
       " ['etɛ'],\n",
       " ['eta'],\n",
       " ['nɔp'],\n",
       " ['nei'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['e'],\n",
       " ['m'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['Xsːi'],\n",
       " ['vwala', 'tsːi'],\n",
       " ['Xma'],\n",
       " ['məwɛ̃mɛ̃'],\n",
       " ['ɲamː'],\n",
       " ['nɲininini'],\n",
       " ['nː'],\n",
       " ['aː'],\n",
       " ['mmː'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['aa'],\n",
       " ['az'],\n",
       " ['a'],\n",
       " ['e'],\n",
       " ['aa'],\n",
       " ['wɛ̃'],\n",
       " ['a'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['və'],\n",
       " ['m'],\n",
       " ['ɛ̃'],\n",
       " ['ɛ̃'],\n",
       " ['hm'],\n",
       " ['a'],\n",
       " ['jɛ'],\n",
       " ['ɛ'],\n",
       " ['mm'],\n",
       " ['aaa'],\n",
       " ['ɛː'],\n",
       " ['m'],\n",
       " ['anani'],\n",
       " ['nanane'],\n",
       " ['jan'],\n",
       " ['ɲa'],\n",
       " ['abububja'],\n",
       " ['sis'],\n",
       " ['a', 'aa', 'aa'],\n",
       " ['ɛː'],\n",
       " ['ɛ'],\n",
       " ['ɑ̃'],\n",
       " ['ɑ̃', 'owa'],\n",
       " ['mja'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['m', 'ɛ', 'a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['m', 'm', 'a', 'm', 'm'],\n",
       " ['a'],\n",
       " ['wu'],\n",
       " ['wɛ'],\n",
       " ['χ', 'wawawəwəwə'],\n",
       " ['əw', 'bəbə'],\n",
       " ['wəbə'],\n",
       " ['b', 'bəbəbəbabəbawəbaba'],\n",
       " ['aba', 'aba'],\n",
       " ['a'],\n",
       " ['m'],\n",
       " ['ala'],\n",
       " ['ha', 'bwə'],\n",
       " ['m'],\n",
       " ['a'],\n",
       " ['aːaː'],\n",
       " ['aː'],\n",
       " ['laɲaː'],\n",
       " ['mju', 'X', 'm'],\n",
       " ['wɛ'],\n",
       " ['m'],\n",
       " ['aː'],\n",
       " ['aː'],\n",
       " ['bɔw'],\n",
       " ['m', 'X'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['m'],\n",
       " ['mm'],\n",
       " ['m'],\n",
       " ['hə'],\n",
       " ['m', 'na'],\n",
       " ['a'],\n",
       " ['i'],\n",
       " ['jala'],\n",
       " ['mm'],\n",
       " ['a'],\n",
       " ['ts'],\n",
       " ['ts', 'tsː'],\n",
       " ['ts', 'vwala', 'ts'],\n",
       " ['eta'],\n",
       " ['m'],\n",
       " ['a'],\n",
       " ['m'],\n",
       " ['esi'],\n",
       " ['esi'],\n",
       " ['təgɔw'],\n",
       " ['nanuː'],\n",
       " ['bəwː', 'X'],\n",
       " ['uwauwauwau'],\n",
       " ['aː'],\n",
       " ['abababvə'],\n",
       " ['ba', 'ɔba'],\n",
       " ['aba'],\n",
       " ['ba'],\n",
       " ['a'],\n",
       " ['mː'],\n",
       " ['aː'],\n",
       " ['a'],\n",
       " ['ba'],\n",
       " ['miɛ̃'],\n",
       " ['a', 'aː'],\n",
       " ['aː'],\n",
       " ['a'],\n",
       " ['eə'],\n",
       " ['wa'],\n",
       " ['ha'],\n",
       " ['aː'],\n",
       " ['awawawaw'],\n",
       " ['ba'],\n",
       " ['aːbə'],\n",
       " ['bwa'],\n",
       " ['a'],\n",
       " ['mː'],\n",
       " ['aa'],\n",
       " ['a'],\n",
       " ['bɛ'],\n",
       " ['a'],\n",
       " ['hi'],\n",
       " ['iː', 'a'],\n",
       " ['wa', 'a'],\n",
       " ['aː'],\n",
       " ['ɛ̃'],\n",
       " ['i'],\n",
       " ['naj'],\n",
       " ['ɔbu'],\n",
       " ['m'],\n",
       " ['aː'],\n",
       " ['u'],\n",
       " ['m'],\n",
       " ['a'],\n",
       " ['aː'],\n",
       " ['i'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['aː'],\n",
       " ['al'],\n",
       " ['aa'],\n",
       " ['wɛ'],\n",
       " ['ə'],\n",
       " ['ə'],\n",
       " ['m'],\n",
       " ['lə', 'nːe'],\n",
       " ['nː'],\n",
       " ['ba'],\n",
       " ['əbvəbvəbvə'],\n",
       " ['a'],\n",
       " ['m'],\n",
       " ['nːne'],\n",
       " ['nananana'],\n",
       " ['mama'],\n",
       " ['ə'],\n",
       " ['əː', 'ne'],\n",
       " ['nːe'],\n",
       " ['əː', 'ne'],\n",
       " ['əː', 'ne'],\n",
       " ['nː'],\n",
       " ['mɛ'],\n",
       " ['aː'],\n",
       " ['amamɛ̃'],\n",
       " ['jah'],\n",
       " ['a'],\n",
       " ['nemamamawə'],\n",
       " ['a'],\n",
       " ['ne'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['ne', 'ne'],\n",
       " ['ne'],\n",
       " ['nː'],\n",
       " ['ubv'],\n",
       " ['nɛj'],\n",
       " ['wɛ'],\n",
       " ['wɛ̃'],\n",
       " ['ɛlɛ̃'],\n",
       " ['mɛ̃'],\n",
       " ['wɛ̃'],\n",
       " ['a'],\n",
       " ['bu'],\n",
       " ['bu'],\n",
       " ['a'],\n",
       " ['ja'],\n",
       " ['la'],\n",
       " ['kəja'],\n",
       " ['wa'],\n",
       " ['a'],\n",
       " ['mɛ'],\n",
       " ['mɛ'],\n",
       " ['mɛ'],\n",
       " ['aː'],\n",
       " ['ba'],\n",
       " ['bɛ'],\n",
       " ['ləmømy'],\n",
       " ['bea'],\n",
       " ['e'],\n",
       " ['a', 'ba'],\n",
       " ['naa'],\n",
       " ['mɛ̃mɛ̃'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['ae'],\n",
       " ['bɛbɛ'],\n",
       " ['aː'],\n",
       " ['he'],\n",
       " ['aa'],\n",
       " ['he'],\n",
       " ['a'],\n",
       " ['aː'],\n",
       " ['aːajajaja'],\n",
       " ['jaj'],\n",
       " ['abababab'],\n",
       " ['aj'],\n",
       " ['ababa'],\n",
       " ['awawawawa'],\n",
       " ['babababa'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['awy'],\n",
       " ['aa'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['jɛ̃'],\n",
       " ['a'],\n",
       " ['ja'],\n",
       " ['la'],\n",
       " ['tada'],\n",
       " ['etatataa'],\n",
       " ['wa'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['aaaaa'],\n",
       " ['e'],\n",
       " ['a'],\n",
       " ['lɛ̃'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['nːe'],\n",
       " ['aa'],\n",
       " ['nːe', 'nːɛ'],\n",
       " ['ne'],\n",
       " ['aha'],\n",
       " ['ad'],\n",
       " ['ba'],\n",
       " ['ba'],\n",
       " ['a'],\n",
       " ['ne'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['nːɛ'],\n",
       " ['nːe'],\n",
       " ['nː', 'nː'],\n",
       " ['wa'],\n",
       " ['nːe'],\n",
       " ['ne', 'nəməby'],\n",
       " ['buu'],\n",
       " ['bɛ̃'],\n",
       " ['ɛbɛw'],\n",
       " ['a'],\n",
       " ['ɛja'],\n",
       " ['e', 'a'],\n",
       " ['ja'],\n",
       " ['aə'],\n",
       " ['awə'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['aa'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['ɛ'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['aːə'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['la'],\n",
       " ['a', 'e'],\n",
       " ['ba'],\n",
       " ['a'],\n",
       " ['ai'],\n",
       " ['a'],\n",
       " ['ava'],\n",
       " ['vaa'],\n",
       " ['eee'],\n",
       " ['wə'],\n",
       " ['wɛ'],\n",
       " ['wa'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['ha'],\n",
       " ['ae'],\n",
       " ['da'],\n",
       " ['m'],\n",
       " ['a'],\n",
       " ['vɛ̃'],\n",
       " ['dɛ̃'],\n",
       " ['ja'],\n",
       " ['na'],\n",
       " ['a'],\n",
       " ['elɛ̃'],\n",
       " ['bɛ̃'],\n",
       " ['aa'],\n",
       " ['ə', 'wə'],\n",
       " ['puʁ', 'diʁ', 'mɛʁsi', 'd', 'tɑ̃', 'zɑ̃', 'tã', 'i', 'di', 'i', 'di', 'si'],\n",
       " ['sː'],\n",
       " ['ks'],\n",
       " ['m'],\n",
       " ['mijɛ'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['ə'],\n",
       " ['a'],\n",
       " ['aː'],\n",
       " ['a'],\n",
       " ['aː'],\n",
       " ['bøːidə'],\n",
       " ['iːdø'],\n",
       " ['eidø'],\n",
       " ['ejydə'],\n",
       " ['jejydydə'],\n",
       " ['edədə'],\n",
       " ['jədø'],\n",
       " ['sedida'],\n",
       " ['ajəta'],\n",
       " ['wəːda'],\n",
       " ['awə'],\n",
       " ['dudus', 'ɛ'],\n",
       " ['jɛ'],\n",
       " ['i'],\n",
       " ['œf'],\n",
       " ['ə'],\n",
       " ['œs'],\n",
       " ['əː'],\n",
       " ['əː'],\n",
       " ['ete', 'eta'],\n",
       " ['əiməta'],\n",
       " ['metɛ'],\n",
       " ['eχtɛ'],\n",
       " ['eepije'],\n",
       " ['ta'],\n",
       " ['yyta'],\n",
       " ['wita'],\n",
       " ['Xta'],\n",
       " ['nənəːtə'],\n",
       " ['wøta'],\n",
       " ['ɛwytə', 'ta'],\n",
       " ['aːga'],\n",
       " ['høm'],\n",
       " ['gəbøt'],\n",
       " ['a'],\n",
       " ['əbə'],\n",
       " ['bəvə'],\n",
       " ['a'],\n",
       " ['m'],\n",
       " ['deta'],\n",
       " ['a'],\n",
       " ['ikɔga'],\n",
       " ['jeutaveta'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['hati'],\n",
       " ['bə'],\n",
       " ['m'],\n",
       " ['itsi'],\n",
       " ['m'],\n",
       " ['ajajta'],\n",
       " ['ajajta'],\n",
       " ['yta'],\n",
       " ['m'],\n",
       " ['əbø'],\n",
       " ['iitɛ̃'],\n",
       " ['kɛ̃'],\n",
       " ['əkɛ̃'],\n",
       " ['aa'],\n",
       " ['ekɛ̃'],\n",
       " ['kɔkɔka'],\n",
       " ['Xka'],\n",
       " ['m'],\n",
       " ['kɔka'],\n",
       " ['kɔka'],\n",
       " ['və'],\n",
       " ['tata'],\n",
       " ['əwei', 'ega'],\n",
       " ['əweigəta'],\n",
       " ['gaː'],\n",
       " ['ejita'],\n",
       " ['jəita'],\n",
       " ['aae'],\n",
       " ['kaka'],\n",
       " ['ha'],\n",
       " ['aaː'],\n",
       " ['østə'],\n",
       " ['ətata'],\n",
       " ['əsː'],\n",
       " ['gə', 'dazida', 'a', 'atatɛzida'],\n",
       " ['ha'],\n",
       " ['inditita'],\n",
       " ['gɔw'],\n",
       " ['leita'],\n",
       " ['kakɔa'],\n",
       " ['əyjːystə'],\n",
       " ['itɛ'],\n",
       " ['aezita'],\n",
       " ['X', 'ta'],\n",
       " ['jelyitɛ'],\n",
       " ['jeyit', 'eta'],\n",
       " ['aeka'],\n",
       " ['ee'],\n",
       " ['bːbʁː', 'ətikaka'],\n",
       " ['əysta'],\n",
       " ['teta'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['ywi'],\n",
       " ['m'],\n",
       " ['wi'],\n",
       " ['e'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['mm'],\n",
       " ['ja'],\n",
       " ['aediita'],\n",
       " ['e', 'ɛ'],\n",
       " ['m', 'm'],\n",
       " ['ejeX'],\n",
       " ['ejejeje', 'a', 'sa', 'sɛ', 'ɛ̃teʁesɑ̃'],\n",
       " ['dəjtə'],\n",
       " ['ea'],\n",
       " ['abaaa'],\n",
       " ['is'],\n",
       " ['edide'],\n",
       " ['isidelis'],\n",
       " ['m'],\n",
       " ['hedizita'],\n",
       " ['tetɔvzita'],\n",
       " ['ee'],\n",
       " ['we'],\n",
       " ['babə'],\n",
       " ['m'],\n",
       " ['mama'],\n",
       " ['m'],\n",
       " ['iiː'],\n",
       " ['e', 'idaaa'],\n",
       " ['jiiida'],\n",
       " ['yyː'],\n",
       " ['ta', 'y'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['mː'],\n",
       " ['ədy', 'vø', 'sa'],\n",
       " ['X', 'tə', 'vø', 'sa'],\n",
       " ['ɔgʁa'],\n",
       " ['gɔggatna'],\n",
       " ['ibøː'],\n",
       " ['bəvzvita'],\n",
       " ['m', 'm'],\n",
       " ['m'],\n",
       " ['ijetta'],\n",
       " ['əys', 'iita'],\n",
       " ['jeyta'],\n",
       " ['jeyta'],\n",
       " ['dəəta'],\n",
       " ['m', 'm'],\n",
       " ['aaː'],\n",
       " ['aaa'],\n",
       " ['evita'],\n",
       " ['ta'],\n",
       " ['aː'],\n",
       " ['m'],\n",
       " ['kɔwga'],\n",
       " ['bawa'],\n",
       " ['buuː'],\n",
       " ['mmː', 'ba'],\n",
       " ['byba'],\n",
       " ['mmm'],\n",
       " ['eezita'],\n",
       " ['əzøta'],\n",
       " ['əvːøita'],\n",
       " ['əvøta'],\n",
       " ['vø', 'itata'],\n",
       " ['jːøː'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['jeɛ'],\n",
       " ['jeɛ'],\n",
       " ['evy'],\n",
       " ['ni'],\n",
       " ['bəe'],\n",
       " ['ə'],\n",
       " ['hɛ̃'],\n",
       " ['iː', 'ɛː'],\n",
       " ['tatatata'],\n",
       " ['m'],\n",
       " ['a'],\n",
       " ['ajaa'],\n",
       " ['ejaaː'],\n",
       " ['ja'],\n",
       " ['ba'],\n",
       " ['ba'],\n",
       " ['ba'],\n",
       " ['aa'],\n",
       " ['aa'],\n",
       " ['tu'],\n",
       " ['ti'],\n",
       " ['jɛ'],\n",
       " ['a'],\n",
       " ['wɛw'],\n",
       " ['ɛɛla'],\n",
       " ['y'],\n",
       " ['wawawawa'],\n",
       " ['ja'],\n",
       " ['wə'],\n",
       " ['m'],\n",
       " ['e'],\n",
       " ['wølɛ'],\n",
       " ['la'],\n",
       " ['aə'],\n",
       " ['talete'],\n",
       " ['aɛ'],\n",
       " ['gi'],\n",
       " ['ə'],\n",
       " ['mː', 'mɑ̃'],\n",
       " ['wə'],\n",
       " ['je'],\n",
       " ['ve'],\n",
       " ['m'],\n",
       " ['vy'],\n",
       " ['bɛ̃'],\n",
       " ['m'],\n",
       " ['aati'],\n",
       " ['a'],\n",
       " ['b'],\n",
       " ['də'],\n",
       " ['a'],\n",
       " ['ba', 'ba'],\n",
       " ['əwøh'],\n",
       " ['aa'],\n",
       " ['wa'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['ahuːhə'],\n",
       " ['y'],\n",
       " ['a'],\n",
       " ['m'],\n",
       " ['a'],\n",
       " ['wə'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['wy', 'wə'],\n",
       " ['wə'],\n",
       " ['bə'],\n",
       " ['da'],\n",
       " ['da'],\n",
       " ['ədɛ'],\n",
       " ['m'],\n",
       " ['iː'],\n",
       " ['ha', 'ijeee'],\n",
       " ['aː'],\n",
       " ['baː'],\n",
       " ['bə'],\n",
       " ['aː'],\n",
       " ['ɔ'],\n",
       " ['m'],\n",
       " ['laʃ'],\n",
       " ['aː'],\n",
       " ['a'],\n",
       " ['ba'],\n",
       " ['ah'],\n",
       " ['u'],\n",
       " ['a'],\n",
       " ['waa'],\n",
       " ['m'],\n",
       " ['eː'],\n",
       " ['ejy'],\n",
       " ['mmm'],\n",
       " ['ə', 'nɛ'],\n",
       " ['iː'],\n",
       " ['a'],\n",
       " ['əwː'],\n",
       " ['wɛ'],\n",
       " ['mm'],\n",
       " ['te'],\n",
       " ['bə'],\n",
       " ['ba'],\n",
       " ['ba'],\n",
       " ['a'],\n",
       " ['ba'],\n",
       " ['bɛ̃'],\n",
       " ['a'],\n",
       " ['he'],\n",
       " ['eː'],\n",
       " ['yː'],\n",
       " ['a'],\n",
       " ['mm'],\n",
       " ['ja'],\n",
       " ['bɔbə'],\n",
       " ['m'],\n",
       " ['papapə', 'χ'],\n",
       " ['eja'],\n",
       " ['ne'],\n",
       " ['ni'],\n",
       " ['mː'],\n",
       " ['bə'],\n",
       " ['bɛ̃'],\n",
       " ['yː'],\n",
       " ['wy'],\n",
       " ['a'],\n",
       " ['ba'],\n",
       " ['aː'],\n",
       " ['a'],\n",
       " ['m'],\n",
       " ['ejɛa'],\n",
       " ['a', 'waə'],\n",
       " ['m'],\n",
       " ['e'],\n",
       " ['ɛː'],\n",
       " ['a'],\n",
       " ['y'],\n",
       " ['a'],\n",
       " ['wi'],\n",
       " ['teda'],\n",
       " ['m'],\n",
       " ['wy'],\n",
       " ['a'],\n",
       " ['ə'],\n",
       " ['ə'],\n",
       " ['ə'],\n",
       " ['bɛ̃'],\n",
       " ['a'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['a'],\n",
       " ['ɛtsi'],\n",
       " ['m', 'aaa', 'm'],\n",
       " ['mː'],\n",
       " ['bwɛ'],\n",
       " ['a'],\n",
       " ['tatata'],\n",
       " ['iːiː'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['wːe'],\n",
       " ['ɛ'],\n",
       " ['elɛm'],\n",
       " ['wəːø'],\n",
       " ['mː'],\n",
       " ['yy'],\n",
       " ['ejoo'],\n",
       " ['wəːə'],\n",
       " ['ɛ', 'ə'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['mː'],\n",
       " ['aja'],\n",
       " ['ejəeɛ'],\n",
       " ['əwə'],\n",
       " ['m'],\n",
       " ['ne'],\n",
       " ['m'],\n",
       " ['dø'],\n",
       " ['baa'],\n",
       " ['ba'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['nːɛ'],\n",
       " ['nn'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['m'],\n",
       " ['yyʃ'],\n",
       " ['iːs'],\n",
       " ['is'],\n",
       " ['ɛ'],\n",
       " ['m'],\n",
       " ['ɛ'],\n",
       " ['ɛ'],\n",
       " ['ɔ'],\n",
       " ['m'],\n",
       " ['nːae'],\n",
       " ['e'],\n",
       " ['tøtə'],\n",
       " ['nː'],\n",
       " ['aa'],\n",
       " ['a'],\n",
       " ['aha'],\n",
       " ['bøja'],\n",
       " ['ne'],\n",
       " ['byyy'],\n",
       " ['m'],\n",
       " ['a'],\n",
       " ['wiɛhih'],\n",
       " ['dap'],\n",
       " ['baaaː'],\n",
       " ['ueɔ'],\n",
       " ['əə'],\n",
       " ['a'],\n",
       " ['a'],\n",
       " ['ba'],\n",
       " ['y'],\n",
       " ['ea'],\n",
       " ['aa'],\n",
       " ['m'],\n",
       " ['naːɛ'],\n",
       " ['wəː'],\n",
       " ['waaa'],\n",
       " ['aː'],\n",
       " ['wəə'],\n",
       " ['aaa'],\n",
       " ['m'],\n",
       " ['i'],\n",
       " ['ɔ', 'ɔ', 'vu'],\n",
       " ['nːi'],\n",
       " ['batie'],\n",
       " ['bɛ', 'zi', 'ne'],\n",
       " ['a'],\n",
       " ['weja'],\n",
       " ['ɛɛ', 'his'],\n",
       " ['b'],\n",
       " ['na'],\n",
       " ['s'],\n",
       " ['na'],\n",
       " ['wə'],\n",
       " ['waw'],\n",
       " ['m'],\n",
       " ['ninini'],\n",
       " ['i'],\n",
       " ['niːu'],\n",
       " ['niː'],\n",
       " ['nː'],\n",
       " ['m'],\n",
       " ['tata'],\n",
       " ['ɛːeː'],\n",
       " ['eː'],\n",
       " ['ats'],\n",
       " ['mːmː'],\n",
       " ['alø'],\n",
       " ['m'],\n",
       " ['ae'],\n",
       " ['ei'],\n",
       " ['aj'],\n",
       " ['alɛ'],\n",
       " ['mː', 'm', 'm'],\n",
       " ['m'],\n",
       " ['aha'],\n",
       " ['mm'],\n",
       " ['aa'],\n",
       " ['aaaaaa'],\n",
       " ['ate'],\n",
       " ['a'],\n",
       " ['weliuitʒuv'],\n",
       " ['ae'],\n",
       " ['mːχ'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['uuu'],\n",
       " ['n'],\n",
       " ['n', 'mm'],\n",
       " ['m'],\n",
       " ['mː'],\n",
       " ['aam'],\n",
       " ['ɛnː'],\n",
       " ['alən'],\n",
       " ['deɛ'],\n",
       " ['m'],\n",
       " ['taːs', 'tatata'],\n",
       " ['teis'],\n",
       " ['mː'],\n",
       " ['m'],\n",
       " ['wə'],\n",
       " ['ə'],\n",
       " ['njɔbam'],\n",
       " ['wɛim'],\n",
       " ['am'],\n",
       " ['a'],\n",
       " ['nː'],\n",
       " ['nːe'],\n",
       " ['wi'],\n",
       " ['a'],\n",
       " ['mam', 'mː'],\n",
       " ['mː'],\n",
       " ['njɛ̃'],\n",
       " ['nɛ', 'tɛ'],\n",
       " ['m'],\n",
       " ['naw'],\n",
       " ['bɔ'],\n",
       " ['n'],\n",
       " ['bum'],\n",
       " ['puma'],\n",
       " ['puma'],\n",
       " ['bama'],\n",
       " ['naːeː'],\n",
       " ['mmm'],\n",
       " ['wa'],\n",
       " ['tɛX'],\n",
       " ['tɛː'],\n",
       " ['dɛ'],\n",
       " ['teɛ'],\n",
       " ['na', 'nːa', 'nːaː'],\n",
       " ['neː', 'nenene'],\n",
       " ['dudule'],\n",
       " ['neeX'],\n",
       " ['is'],\n",
       " ['m'],\n",
       " ['naaaː'],\n",
       " ['naaaː'],\n",
       " ['wu'],\n",
       " ['eːsize'],\n",
       " ['əejejije'],\n",
       " ['i'],\n",
       " ['ɔwa'],\n",
       " ['m'],\n",
       " ['mː'],\n",
       " ['əː'],\n",
       " ['weː'],\n",
       " ['m'],\n",
       " ['ə'],\n",
       " ['m'],\n",
       " ['mː'],\n",
       " ['is'],\n",
       " ['nː', 'ohis'],\n",
       " ['eːɛts'],\n",
       " ['i'],\n",
       " ['eː'],\n",
       " ['iːs'],\n",
       " ['na'],\n",
       " ['a'],\n",
       " ['e'],\n",
       " ['s'],\n",
       " ['i'],\n",
       " ['m'],\n",
       " ['ja'],\n",
       " ['m'],\n",
       " ['dɔm'],\n",
       " ['duː'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['mmm'],\n",
       " ['duː'],\n",
       " ['əː'],\n",
       " ['m'],\n",
       " ['wːa'],\n",
       " ['abuujɛl'],\n",
       " ['uwe'],\n",
       " ['ɔwəwəwəwə'],\n",
       " ['mː'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['mm'],\n",
       " ['mːχ', 'bu'],\n",
       " ['mː'],\n",
       " ['m', 'm'],\n",
       " ['m', 'mː'],\n",
       " ['m'],\n",
       " ['m', 'a'],\n",
       " ['dɔ'],\n",
       " ['mi'],\n",
       " ['mɛː'],\n",
       " ['ɛː'],\n",
       " ['gla'],\n",
       " ['dɛ'],\n",
       " ['eeɛ'],\n",
       " ['atɛ'],\n",
       " ['e'],\n",
       " ['mm'],\n",
       " ['mː'],\n",
       " ['maɛ'],\n",
       " ['a'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['jeX'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['ɛːʃ'],\n",
       " ['wa'],\n",
       " ['mm'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['ti', 'tateta'],\n",
       " ['tatetɛ̃'],\n",
       " ['də'],\n",
       " ['bɔ'],\n",
       " ['bu'],\n",
       " ['am'],\n",
       " ['aaa'],\n",
       " ['am'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['m'],\n",
       " ['nuzuzuXɛ'],\n",
       " ['vuvːavəvavavavavaaa'],\n",
       " ['tyː'],\n",
       " ['mː'],\n",
       " ['teun'],\n",
       " ['mm'],\n",
       " ['m', 'mː'],\n",
       " ['ɛ'],\n",
       " ['ə'],\n",
       " ['a'],\n",
       " ['mː'],\n",
       " ['y'],\n",
       " ['m'],\n",
       " ['uf'],\n",
       " ['aaː'],\n",
       " ['u'],\n",
       " ['mː', 'am'],\n",
       " ['a'],\n",
       " ['am'],\n",
       " ['bɔm'],\n",
       " ['zəzə'],\n",
       " ['bɛ̃'],\n",
       " ['bwa'],\n",
       " ['tsː'],\n",
       " ['mi'],\n",
       " ['ii'],\n",
       " ['m'],\n",
       " ['na'],\n",
       " ['na'],\n",
       " ['ja'],\n",
       " ['ma'],\n",
       " ['na'],\n",
       " ['a'],\n",
       " ['ja'],\n",
       " ['ma', 'na'],\n",
       " ['ma', 'ma'],\n",
       " ['ma'],\n",
       " ['əə'],\n",
       " ['aə'],\n",
       " ['a'],\n",
       " ['is'],\n",
       " ['is'],\n",
       " ['la'],\n",
       " ...]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = pho_antoine['contenu'].str.split(' ').tolist()\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('də',), 179)\n",
      "(('dø',), 197)\n",
      "(('aː',), 154)\n",
      "(('nɑ̃',), 307)\n",
      "(('na',), 104)\n",
      "(('t',), 138)\n",
      "(('va',), 211)\n",
      "(('vwatyʁ',), 139)\n",
      "(('ʒə',), 212)\n",
      "(('l',), 368)\n",
      "(('mɛ',), 167)\n",
      "(('e',), 856)\n",
      "(('ɛ',), 485)\n",
      "(('ɛ̃',), 201)\n",
      "(('tu',), 118)\n",
      "(('ɑ̃',), 128)\n",
      "(('X',), 441)\n",
      "(('œ̃',), 245)\n",
      "(('pa',), 700)\n",
      "(('wiʃ',), 125)\n",
      "(('la',), 1023)\n",
      "(('se',), 290)\n",
      "(('ʒ',), 318)\n",
      "(('œ̃̃',), 270)\n",
      "(('vø',), 179)\n",
      "(('si',), 148)\n",
      "(('a', 'a'), 100)\n",
      "(('fɛ',), 102)\n",
      "(('ɔ̃',), 225)\n",
      "(('o',), 220)\n",
      "(('wi',), 855)\n",
      "(('papa',), 163)\n",
      "(('fe',), 129)\n",
      "(('lə',), 342)\n",
      "(('bɛ̃',), 214)\n",
      "(('d',), 116)\n",
      "(('i',), 487)\n",
      "(('ø',), 128)\n",
      "(('pø',), 114)\n",
      "(('kwa',), 129)\n",
      "(('ɔ',), 209)\n",
      "(('mamɑ̃',), 211)\n",
      "(('dɑ̃',), 124)\n",
      "(('a',), 1427)\n",
      "(('χ',), 104)\n",
      "(('ty',), 237)\n",
      "(('twa',), 103)\n",
      "(('ʒ', 'e'), 114)\n",
      "(('sa',), 648)\n",
      "(('ɛl',), 137)\n",
      "(('nɔ̃',), 579)\n",
      "(('lɛ',), 189)\n",
      "(('yn',), 199)\n",
      "(('u',), 108)\n",
      "(('ə',), 253)\n",
      "(('mwa',), 249)\n",
      "(('il',), 173)\n",
      "(('kɔm',), 139)\n",
      "(('mː',), 121)\n",
      "(('sɛ',), 573)\n",
      "(('ja',), 138)\n",
      "(('isi',), 109)\n",
      "(('m',), 627)\n"
     ]
    }
   ],
   "source": [
    "freq_seqs = seqmining.freq_seq_enum(sequences, 100)\n",
    "for seq in freq_seqs:\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "df = pho_antoine[{'age', 'contenu'}].groupby('age') # On regroupe les phrases par l'age de l'enfant (par enregistrement)\n",
    "df = pd.DataFrame(df)\n",
    "print(len(df[1][0]['contenu']))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pho_antoine[{'age', 'contenu'}].groupby('age') # On regroupe les phrases par l'age de l'enfant (par enregistrement)\n",
    "df = pd.DataFrame(df)\n",
    "len(df[1][0]['contenu']) # Pour le 1er enregistrement on a 186 phrases\n",
    "df[1][0]['contenu'].str.split(' ').tolist()\n",
    "df[1][1]['contenu'].values\n",
    "sequences = []\n",
    "for i in range(df.shape[0]):\n",
    "    tup = tuple(df[1][i]['contenu'].str.split(' ').tolist())\n",
    "    sequences.append(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0] # On retrouve notre liste des mots par phrase du 1er enregistrement\n",
    "len(sequences[0])\n",
    "relim_input = itemmining.get_relim_input(sequences[6])\n",
    "\n",
    "item_sets = itemmining.relim(relim_input, min_support=50)\n",
    "item_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item : phonème"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quels sont les phonèmes uniques présent dans le corpus ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# /!\\ TODO /!\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ɛ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>̃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ɔ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ː</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ɲ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ɑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>χ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ʁ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>œ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ʃ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ʒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ɥ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ŋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ɣ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ɜ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ɵ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ʏ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>ε</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>é</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0    \n",
       "1   a\n",
       "3   h\n",
       "4   j\n",
       "5   b\n",
       "6   ə\n",
       "7   i\n",
       "8   w\n",
       "9   y\n",
       "10  ɛ\n",
       "11  d\n",
       "12   \n",
       "13  X\n",
       "14  ̃\n",
       "15  t\n",
       "16  e\n",
       "17  n\n",
       "18  ɔ\n",
       "19  p\n",
       "20  m\n",
       "21  s\n",
       "22  ː\n",
       "23  v\n",
       "24  l\n",
       "25  ɲ\n",
       "26  z\n",
       "27  u\n",
       "28  ɑ\n",
       "29  o\n",
       "30  χ\n",
       "31  g\n",
       "32  k\n",
       "33  ø\n",
       "34  ʁ\n",
       "35  œ\n",
       "36  f\n",
       "37  ʃ\n",
       "38  ʒ\n",
       "39  .\n",
       "40  :\n",
       "41  ɥ\n",
       "42  r\n",
       "43  ŋ\n",
       "44  c\n",
       "45  ɣ\n",
       "46  x\n",
       "47  ɜ\n",
       "48  ɵ\n",
       "49  +\n",
       "50  ʏ\n",
       "51  q\n",
       "52  M\n",
       "53  9\n",
       "54  I\n",
       "55  R\n",
       "56  ε\n",
       "57  é"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = pho_antoine['contenu'].str.split('').tolist()\n",
    "pho_col = pd.DataFrame(transactions)\n",
    "pho_col = pd.unique(pho_col.values.ravel())\n",
    "pho_col = pd.DataFrame(pho_col)\n",
    "pho_col = pho_col.dropna()\n",
    "print(len(pho_col))\n",
    "pho_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indexed_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-de52994186b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtransactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtransactions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexed_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'indexed_list' is not defined"
     ]
    }
   ],
   "source": [
    "#corpus = pho_antoine['contenu'].str.split(' ').tolist()\n",
    "#transactions = []\n",
    "#for list in corpus:\n",
    "#    transactions.append(indexed_list(list)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Récupérer les phrases qui contiennent une chaîne de caractère étrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " phonème :  - 16112\n",
      " phonème : a - 8865\n",
      " phonème : h - 284\n",
      " phonème : j - 1643\n",
      " phonème : b - 1829\n",
      " phonème : ə - 2072\n",
      " phonème : i - 4898\n",
      " phonème : w - 3034\n",
      " phonème : y - 1531\n",
      " phonème : ɛ - 3961\n",
      " phonème : d - 2070\n",
      " phonème :   - 8167\n",
      " phonème : X - 457\n",
      " phonème : ̃ - 4658\n",
      " phonème : t - 3592\n",
      " phonème : e - 3574\n",
      " phonème : n - 2652\n",
      " phonème : ɔ - 3435\n",
      " phonème : p - 3035\n",
      " phonème : m - 3494\n",
      " phonème : s - 3439\n",
      " phonème : ː - 2039\n",
      " phonème : v - 1778\n",
      " phonème : l - 3613\n",
      " phonème : ɲ - 90\n",
      " phonème : z - 496\n",
      " phonème : u - 1929\n",
      " phonème : ɑ - 2136\n",
      " phonème : o - 1456\n",
      " phonème : χ - 107\n",
      " phonème : g - 857\n",
      " phonème : k - 2651\n",
      " phonème : ø - 997\n",
      " phonème : ʁ - 3445\n",
      " phonème : œ - 880\n",
      " phonème : f - 1166\n",
      " phonème : ʃ - 1222\n",
      " phonème : ʒ - 1039\n",
      " phonème : . - 5\n",
      " phonème : : - 4\n",
      " phonème : ɥ - 331\n",
      " phonème : r - 119\n",
      " phonème : ŋ - 11\n",
      " phonème : c - 21\n",
      " phonème : ɣ - 55\n",
      " phonème : x - 2\n",
      " phonème : ɜ - 2\n",
      " phonème : ɵ - 21\n",
      " phonème : + - 1\n",
      " phonème : ʏ - 2\n",
      " phonème : q - 2\n",
      " phonème : M - 1\n",
      " phonème : 9 - 14\n",
      " phonème : I - 2\n",
      " phonème : R - 1\n",
      " phonème : ε - 1\n",
      " phonème : é - 1\n"
     ]
    }
   ],
   "source": [
    "for pho in pho_col.values:\n",
    "    #print(str(pho[0]))\n",
    "    print(' phonème : '+str(pho[0])+' - '+ str(len(df_item_in_rows(str(pho[0]), pho_antoine))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Frequent Itemset Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Pattern Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Retranscription phonémique\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Phonémes indexés\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but est d'indexer les phonèmes en fonction de leur placement dans un mot:\n",
    " - Le phonème est placé en début de mot\n",
    " - Le phonème est placé en milieu de mot\n",
    " - Le phonème est placé en fin de mot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexed(x):\n",
    "    \"\"\"\n",
    "        Index de phonème\n",
    "        retourne list contenant les phonèmes indexés\n",
    "        param : x (string) un mot phonétique\n",
    "    \"\"\"\n",
    "    l = []\n",
    "    # On décide de recoder les phonèmes suivant pour des raisons d'encodage\n",
    "    #x=x.replace('ʁ','r') \n",
    "    x=x.replace('ɑ̃','0')\n",
    "    x=x.replace('ɔ̃','1') \n",
    "    x=x.replace('ɛ̃','2') \n",
    "    x=x.replace('œ̃','3') \n",
    "    x=x.replace('tʁ','4')\n",
    "    x=x.replace('kʁ','5')\n",
    "    x=x.replace('dʁ','6')\n",
    "    x=x.replace('gʁ','7')\n",
    "    \n",
    "    for i in range(0,len(x)): # On parcours chaque charactère du mot\n",
    "        suff = '_d'           # On considère que le 1er charactère lu est au début du mot\n",
    "        if(i>0):              # Ensuite on considère que tout les autres charactères sont en milieu de mot\n",
    "            suff = '_m'\n",
    "            if(i==len(x)-1):  # Sauf pour le dernier charactère lu\n",
    "                suff = '_f'   \n",
    "        l.append(x[i]+suff)   # On ajouter le phonème indexé \n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = 'az'\n",
    "test = 'kʁɑ̃liʁ'\n",
    "#test = 'vœgaʃ'\n",
    "#test = 'e'\n",
    "indexed(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention la longueur des mots n'est plus la même"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'kʁɑ̃liʁ'\n",
    "print(len(x))\n",
    "print(len(indexed(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# /!\\ Verifier dans chaque corpus que les phonèmes que l'ont a recodé sont bien écrit de la même façon par les retranscripteurs /!\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexed_list(list):\n",
    "    '''\n",
    "        param : list (list)\n",
    "        return\n",
    "    '''\n",
    "    l = []\n",
    "    for word in list:\n",
    "        l.append(indexed(word))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pho_antoine[-1:]['contenu'].str.split(' ').tolist()\n",
    "a = a[0]\n",
    "print(a)\n",
    "print(indexed_list(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ['eː','bɛ','vœga','gatœ̃','kaka','dœjøkɛka','m','taka','dɛka','gøgega','kaga','gɛda','eka','memː','kakam','kaka X','gli',\n",
    " 'ta','da','lœ','gɛga','ɛ̃ɑ̃','iː','gɛga','ga','ga','gɛga','ɛɛeeiː','iii','gegɛga','gagaga','mœdada','mːmmaː','mamamamamamœkaga',\n",
    " 'gaʁd','awaøː','œgaʁd','vega','ge','ga','œ̃','ɛ','mː','vøga','emɛ','myjajaja','lala','ejɛːajajajajajɛjɛːɛ',\n",
    " 'ejɛajajajajajajɛɛ','nenenenenja','øgagagagaga','øga','nana','ga','a','ɔːmaː','øgaga','bølala','ala','m',\n",
    " 'maːmmmœmœmː','øgalaøwa','la','X œgaga œga œga','gagaga','ma','gaga','ga a aː','a gagagaga','œ','gaga','aga',\n",
    " 'gagad','bøgaga','øga','gaga','bøga','aː','gaga','gaga','ala','ga','gala','ga']\n",
    "\n",
    "# indexed_list(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item : phonème indexé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pho_antoine['contenu'].str.split(' ').tolist()\n",
    "transactions = []\n",
    "for list in corpus:\n",
    "    transactions.append(indexed_list(list)[0])\n",
    "#transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_col = pd.DataFrame(transactions)\n",
    "item_col = pd.unique(item_col.values.ravel())\n",
    "item_col = pd.DataFrame(item_col)\n",
    "item_col = item_col.dropna()\n",
    "print(len(item_col))\n",
    "item_col.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre collection d'item est de 153 phonèmes indexés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Frequent Itemset Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relim_input = itemmining.get_relim_input(transactions)\n",
    "item_sets = itemmining.relim(relim_input, min_support=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support minimun : 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# item_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assocation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = assocrules.mine_assoc_rules(item_sets, min_support=10, min_confidence=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Support minimum : 10\n",
    "    Confidence minimum : 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
